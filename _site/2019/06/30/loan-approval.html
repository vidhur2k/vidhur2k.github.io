<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Classifying Loans based on the risk of defaulting</title>
    <meta name="description" content="A simple, whitespace, helvetica based portfolio theme.
">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="http://localhost:4000/2019/06/30/loan-approval.html">

    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <nav class="site-nav">

      <div class="trigger">
        <!--  instead of blog -->
        <a class="page-link" href="/">Blog</a>

        
          
          <a class="page-link" href="/about/">About Me</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/portfolio/">Portfolio</a>
          
        

        <a class="page-link" href="/Resume 2019-20.pdf" target="_blank">Resume</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Classifying Loans based on the risk of defaulting</h1>
    <p class="post-meta">June 30, 2019 — 03:59</p>
  </header>

    <h2 id="a-short-introduction"><strong>A Short Introduction</strong></h2>
<p>Classification is one of the classical problems in Supervised Learning where we attempt to train a model to classify data points into <em>n</em> distinct classes. As I was browsing through datasets online, I came across one that contained information on 1000 loan applicants (from both urban and rural areas). One of the columns in the data table was whether or not the loan was approved. An idea immediately struck me:</p>

<blockquote>
  <p>What if we could build a model to predict whether an applicant’s loan would be approved or denied depending on his or her risk of defaulting?</p>
</blockquote>

<p>This would be a garden-variety classification problem, where we have 2 distinct classes to group our data by: a loan approval or a loan denial.</p>

<p>It is important to not be hasty and start training models on the raw and unexplored data. Preprocessing the data not only helps us smooth out inconsistencies (missing values and outliers), but also gives us a comprehensive understanding of the data which in turn aids us in our model selection process.</p>

<p>This end-to-end Machine Learning project is primarily based on Python. I have used the following libraries to help me achieve the objective:</p>

<ol>
  <li><strong>Numpy</strong> for mathematical operations.</li>
  <li><strong>Pandas</strong> for data exploration and analysis</li>
  <li><strong>Matplotlib</strong> and <strong>Seaborn</strong> for data visualization</li>
  <li><strong>Scikit-learn</strong> for model training, cross-validation, and evaluation metrics.</li>
</ol>

<h2 id="importing-the-libraries"><strong>Importing the libraries</strong></h2>
<p>Let us perform all the necessary imports beforehand</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span></code></pre></figure>

<p>Once we have all the libraries necessary, we can read the data in from CSV file using Pandas.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'credit_risk.csv'</span><span class="p">)</span></code></pre></figure>

<h2 id="understanding-the-features"><strong>Understanding the Features</strong></h2>
<p>Before moving forward with the data exploration, I always like to understand the features that 
I will be dealing with on a superficial level. Doing this will help us put into words any mathematical
interpretations we make. The following are the list of features that we have from our dataset:</p>

<ol>
  <li><strong>Loan ID</strong>: The ID given by the bank to the loan request.</li>
  <li><strong>Gender</strong>: The gender of the primary applicant.</li>
  <li><strong>Married</strong>: Binary variable indicating the marital status of the primary applicant.</li>
  <li><strong>Dependents</strong>: Number of dependents of the primary applicant.</li>
  <li><strong>Education</strong>: Binary variable indicating whether or not the primary applicant has graduated high school.</li>
  <li><strong>Self_Employed</strong>: Binary variable indicating whether or not the individual is self-employed.</li>
  <li><strong>Applicant Income</strong>: The income of the primary applicant.</li>
  <li><strong>Co-Applicant Income</strong>: The income of the co-applicant.</li>
  <li><strong>Loan Amount</strong>: The amount the applicant wants to borrow.</li>
  <li><strong>Loan Amount Term</strong>: The term over which the applicant would repay the loan.</li>
  <li><strong>Credit History</strong>: Binary variable representing whether the client had a good history or a bad history.</li>
  <li><strong>Property Area</strong>: Categorical variable indicating whether the applicant was from an urban, semiurban, or a rural area.</li>
  <li><strong>Loan Status</strong>: Variable indicating whether the loan was approved or denied. This will be our output (dependent) variable.</li>
</ol>

<p>Of all these variables, I have chosen the Gender, Applicant Income, Loan Amount, and Property Area as the ones to delve deeper into. It is important
to look at the data from multiple angles, i.e., independently and in relation to the other variables. This points out any red flags in the dstributions of the variables and also reveals interesting relationships amongst them.</p>

<h2 id="visualizing-the-data"><strong>Visualizing the data</strong></h2>
<p>Humans are visual creatures, and a majority of us process information better when we see it. Thus, when it comes to understanding our data, taking
a visual approach is far more effective than manually crunching hundreds of rows worth of numbers. I have plotted visualizations that show the distributions
of important features as well as interesting relationships between some of the features. How did I decide which features are important? I used the correlation matrix,
where the value at (i, j) represents how strongly <em>feature i</em> is correlated to <em>feature j</em>.</p>

<p>We can use seaborn’s heatmap visualization to help us understand the correlation matrix.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">corr</span><span class="p">())</span></code></pre></figure>

<p>Before we begin explorng our feature variables, I wanted to have a look at our dependent variable, i.e., the one we are attempting to predict using the model. Shown below is a simple countplot by class.</p>

<p><img src="/img/Loan-Approval/loanstatus.png" alt="Tensorboard Architecture" /></p>

<p>There is a clear imbalance between the classes, and that can be very dangerous! Our model may end up highly biased towards the majority class, which
is not ideal when it comes to the model’s generalization capabilities. For that reason, we will perform feature scaling to ensure uniformity, and also make sure that the algorithm we use to build the model is ‘aware’ that the classes are imbalanced.</p>

<p><img src="/img/Loan-Approval/corr.png" alt="Tensorboard Architecture" /></p>

<p>I was also curious about how the property area and the loan amount jointly affected the authorization of the loan. Let us have a look at a relational plot of the loan amount against approval separated by the property area.
<img src="/img/Loan-Approval/proparea.png" alt="Tensorboard Architecture" /></p>

<p>It will help if we divide the data into approved and unapproved loans and look at the count of how many of those loan applications came from each property area. 
<img src="/img/Loan-Approval/aproparea.png" alt="Tensorboard Architecture" /> <img src="/img/Loan-Approval/uproparea.png" alt="Tensorboard Architecture" /></p>

<p>From the looks of it, it looks like a higher fraction of the rural loan applications are denied. I calculated the ratio of approved loans from each property area, and the numbers corroborate our hypothesis.</p>

<ol>
  <li><strong>Urban Approval Ratio:  0.7368421052631579</strong></li>
  <li><strong>Semiurban Approval Ratio:  0.7822349570200573</strong></li>
  <li><strong>Rural Approval Ratio:  0.6448275862068965</strong></li>
</ol>

<h2 id="cleaning-the-data"><strong>Cleaning the data</strong></h2>
<p>Now that we’ve explored the data visually to better understand what we’re dealing with, its time to preprocess our data
in order to make sure that the model we train is not subject to any noisy training instances (in the context of ML, the term “training instance” refers to a
single data point that is part of the dataset used to train and test the model.) I have divided our preprocessing step into the following substeps:</p>
<ol>
  <li>Check for and replace missing values if necessary.</li>
  <li>Remove unncessary features.</li>
  <li>Encode categorical features to make sure they are properly interpreted.</li>
</ol>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># **Replace the categorical values with the numeric equivalents that we have above**
</span><span class="n">categoricalFeatures</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Property_Area'</span><span class="p">,</span> <span class="s">'Gender'</span><span class="p">,</span> <span class="s">'Married'</span><span class="p">,</span> <span class="s">'Dependents'</span><span class="p">,</span> <span class="s">'Education'</span><span class="p">,</span> <span class="s">'Self_Employed'</span><span class="p">]</span>

<span class="c1"># **Iterate through the list of categorical features and one hot encode them.**
</span><span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">categoricalFeatures</span><span class="p">:</span>
    <span class="n">onehot</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">prefix</span><span class="o">=</span><span class="n">feature</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">onehot</span><span class="p">)</span></code></pre></figure>

<p>Note that data preprocessing is by no means formulaic, and the steps that I am about to take are subjective.</p>

<h2 id="training-the-model"><strong>Training the model</strong></h2>
<p>Fin*ally, the exciting bit! We have our data prepared, and we shall serve it to our model to devour! The algorithm that I chose for this particular case was Logistic Regression. It is one of the simpler supervised learning algorithms, but has proven to be extremely reliant in a variety of instances.</p>

<p>Before we train the model, we shall utilize Scikit-learn’s inbuilt train-test split module to randomly split our dataset into training and testing subsets. We shall split it according to the 80-20 rule (this seems an arbitrary and scientifically ungrounded choice, but it is known to “just work” when it comes to training models).</p>

<p>Let us begin by instantiating a Logistic Regression object (we will be using scikit-learn’s module) and split the dataset in the aforementioned way.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Liblinear is a solver that is effective for relatively smaller datasets.
</span><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s">'liblinear'</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span></code></pre></figure>

<p>Notice that we specify that the weights of the classes in question have to be balanced. This ensures that the classes are appropriately weighted, thereby eliminating any bias created by an imbalance in the classes. If you are curious as to how the classes are weighted, <a href="https://chrisalbon.com/machine_learning/logistic_regression/handling_imbalanced_classes_in_logistic_regression/">this article by Chris Albon</a>  provides a comprehensive explanation.</p>

<p>Before we pass in the data, let us perform feature scaling using Scikit-learn’s Standard Scaler.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">data_std</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># We will follow an 80-20 split pattern for our training and test data
</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span></code></pre></figure>

<p>Now that we have everything we need, we fit the model to the training data.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></figure>

<h2 id="evaluating-the-performance-of-the-model"><strong>Evaluating the performance of the model</strong></h2>
<p>It is just as (if not more) important to evaluate the performance of algorithms as it is understanding and implementing them. I’ve provided a brief but comprehensive introduction to the confusion matrix and the three fundamental evaluation metrics for classification.</p>

<p>A Confusion matrix is simply a tabular visualization of the error rates of the matrix that is widely used to evaluate the performance of 
a classification algorithm. The rows of the matrix represent the actual label of the instance, while the columns reprsent the predicted label. In our case, we have a 2x2 matrix as we are performing binary classification. To generalize, an “n-ary” classification problem will have an nxn confusion matrix.</p>

<p>The <em>(m, n)</em> entry of the confusion matrix tells us how many instances whose correct label is class <em>m</em> was classified into class <em>n</em>. So, the diagonal entries of our matrix represents correct classifications and the rest represent the incorrect ones. In binary classification, the diagonal entries are commonly referred to as the <strong>true positives</strong> and the <strong>true negatives</strong>, and the other two are the <strong>false positives</strong> and <strong>false negatives</strong>.</p>

<p>Now that the model has been trained, we will use the test data that we sieved from the original dataset to evaluate how well our model generalizes to the data. I have divided the evaluation process in the following way:</p>

<ol>
  <li>Vectorize the predictions made by the model and build a confusion matrix.</li>
  <li>Use the confusion matrix</li>
</ol>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># We will compare this vector of predictions to the actual target vector to determine the model performance.
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Build the confusion matrix.
</span><span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># name of classes
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">class_names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">class_names</span><span class="p">)</span>

<span class="c1"># The heatmap requires that we pass in a dataframe as the argument
</span><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"YlGnBu"</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">"g"</span><span class="p">)</span>

<span class="c1"># Configure the heatmap parameters
</span><span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s">"top"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Confusion matrix'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Actual label'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Predicted label'</span><span class="p">)</span></code></pre></figure>

<p><img src="/img/Loan-Approval/confmat.png" alt="Tensorboard Architecture" /></p>

<p>At a glance, most of our classifications seem to be concentrated in the diagonal entries. An excellent start! Recall that we said the matrix gave us
the error rates. But, its hard to gain a concrete numerical measure of the model’s performance from the matrix alone. Thus, we use the values from the matrix to compute the three fundamental classification performance measures: <strong>accuracy, precision, and recall</strong>.</p>

<ol>
  <li>Precision:</li>
  <li>Recall</li>
  <li>Accuracy</li>
</ol>

<p>Scikit-learn’s inbuilt metrics module lets us compute these metrics in a single line of code!</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Print out our performance metrics
</span><span class="k">print</span><span class="p">(</span><span class="s">"Accuracy:"</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Precision:"</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s">'Y'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Recall:"</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s">'Y'</span><span class="p">))</span></code></pre></figure>

<p>For our model, the metrics’ values turned out to be:</p>
<ol>
  <li><strong>Accuracy: 0.8116883116883117</strong></li>
  <li><strong>Precision: 0.875</strong></li>
  <li><strong>Recall: 0.8504672897196262</strong></li>
</ol>

<p>It is an accepted practice to use precision and recall in conjunction to gauge the performance of a classfication model as one could simply
use instances that he or she knows would result in a correct prediction to gain a perfect precision score. In other words, if I have one training instance that I knew belonged to the positive class I would make sure that the model classifies only that instance into the positive class. The F1 score is a metric that is a harmonic sum of the precision and recall. It is a singular measure of a model’s performance and takes into account both the precision and recall, thus making sure that we do not have to go through the hassle of interpreting the numbers manually. Yet again, Scikit learn’s metrics module comes to the rescue!</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="s">"F1 Score:"</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s">'Y'</span><span class="p">))</span></code></pre></figure>

<p><strong>F1 Score: 0.8625592417061612</strong></p>

<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>Alright, awesome! We sucessfully trained a model that can predict the response to a loan applicant based on the data we have on them. To do this at scale would be futile for us humans, but the performance of the classifier shows us just how powerful these techniques can be. Classification is but one of the multitude of techniques available as part of the Predictive Modeling toolbox. I hope that this has proven to be an informative and engaging introduction to the topic. Happy coding!</p>

  </article>

</div>

      </div>
    </div>

    <!-- <footer class="site-footer">

  <div class="wrapper">
  	<p>This site was built using <a href="http://jekyllrb.com" target="_blank">Jekyll</a> and is hosted on <a href="https://github.com" target="_blank">Github</a> Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a> and text generated with <a href="http://hipsum.co" target="_blank">Hipster Ipsum</a>. &#169; 2015</p>
  </div>

</footer>
 -->

  </body>

</html>
